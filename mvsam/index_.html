<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="MV-SAM: Multi-view Promptable Segmentation using Pointmap Guidance">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="KEYWORD1, KEYWORD2, KEYWORD3, machine learning, computer vision, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content="FIRST_AUTHOR_NAME, SECOND_AUTHOR_NAME">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="INSTITUTION_OR_LAB_NAME">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="MV-SAM: Multi-view Promptable Segmentation using Pointmap Guidance">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title> MV-SAM: Multi-view Promptable Segmentation using Pointmap Guidance </title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="./static/images/favicon.jpg">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "MV-SAM: Multi-view Promptable Segmentation using Pointmap Guidance",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


<!-- Scroll to Top Button -->
<button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
  <i class="fas fa-chevron-up"></i>
</button>

<!-- More Works Dropdown -->
<div class="more-works-container">
  <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
    <i class="fas fa-flask"></i>
    More Works
    <i class="fas fa-chevron-down dropdown-arrow"></i>
  </button>
  <div class="more-works-dropdown" id="moreWorksDropdown">
    <div class="dropdown-header">
      <h4>More Works from Our Lab</h4>
      <button class="close-btn" onclick="toggleMoreWorks()">
        <i class="fas fa-times"></i>
      </button>
    </div>
    <div class="works-list">
      <!-- TODO: Replace with your lab's related works -->
      <a href="https://arxiv.org/abs/PAPER_ID_1" class="work-item" target="_blank">
        <div class="work-info">
          <!-- TODO: Replace with actual paper title -->
          <h5>Quantile Rendering: Efficiently Embedding High-dimensional Feature on 3D Gaussian Splatting</h5>
          <!-- TODO: Replace with brief description -->
          <p>Efficient Gaussian perception network with SOTA performance</p>
          <!-- TODO: Replace with venue and year -->
          <span class="work-venue">arXiv25</span>
        </div>
        <i class="fas fa-external-link-alt"></i>
      </a>
    </div>
  </div>
</div>

<main id="main-content">
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          
          <!-- TODO: Replace with your paper title -->
          <h1 class="title is-1 publication-title">
            <span style="color:#76B900;">MV-SAM</span>: Multi-view Promptable Segmentation using Pointmap Guidance
          </h1>

          <div class="is-size-5 publication-authors">
            <!-- TODO: Replace with your paper authors and their personal links -->
              <span class="author-block"><a href="https://jeongyw12382.github.io" target="_blank">Yoonwoo Jeong</a><sup>1,2</sup>,</span>
              <span class="author-block"><a href="https://sunset1995.github.io" target="_blank">Cheng Sun</a><sup>1</sup>,</span>
              <span class="author-block"><a href="https://research.nvidia.com/person/frank-wang" target="_blank">Yu-Chiang Frank Wang</a><sup>1</sup>,</span>
              <span class="author-block"><a href="https://cvlab.postech.ac.kr/~mcho" target="_blank">Minsu Cho</a><sup>2</sup>, and</span>
              <span class="author-block"><a href="https://jaesung-choe.github.io" target="_blank">Jaesung Choe</a><sup>1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <!-- TODO: Replace with your institution and conference/journal info -->
            <span class="author-block">NVIDIA<sup>1</sup>, POSTECH<sup>2</sup> <br>arXiv25</span>
            <!-- TODO: Remove this line if no equal contribution -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1-F1746CF2SJ6V5avXPunSj3VFo6-LetM/view?usp=sharing" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"> <i class="fas fa-file-pdf"></i> </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- TODO: Replace with your GitHub repository URL -->
              <span class="link-block">
                  <a href="https://gitlab-master.nvidia.com/jchoe/mv_sam" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="highlight-section">
  <h2 class="project-highlight">
    <strong><span class="highlight">MV-SAM</span></strong> extends Segment Anything into multi-view without annotated 3D or video datasets using pointmap.
  </h2>
</section>


<style>
  .highlight-section {
    text-align: center;
    margin: 60px auto;
    padding: 0 20px;
    max-width: 900px;
  }

  .project-highlight {
    font-size: 1.8rem;
    font-weight: 500;
    color: #222;
    line-height: 1.6;
  }

  .highlight {
    color: #76B900;
    font-weight: 900;
  }
</style>


<!-- Video Teaser -->
<video 
  id="tree" 
  autoplay 
  controls 
  muted 
  preload="metadata" 
  style="width: 100%; max-width: 1600px; display: block; margin: 0 auto; border-radius: 12px;"
>
  <source src="static/videos/banner.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

<script>
  const video = document.getElementById('tree');

  // 반복 구간 (단위: 초)
  const startTime = 5;
  const endTime = 10;

  // 영상이 로드되면 시작 시점으로 이동
  video.addEventListener('loadedmetadata', () => {
    video.currentTime = startTime;
  });

  // 현재 시간이 endTime을 넘으면 다시 startTime으로 되돌림
  video.addEventListener('timeupdate', () => {
    if (video.currentTime >= endTime) {
      video.currentTime = startTime;
      video.play();
    }
  });
</script>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Promptable segmentation has emerged as a powerful paradigm in computer vision, enabling users to guide models in parsing complex scenes with prompts such as clicks, boxes, or textual cues. Recent advances, exemplified by the Segment Anything Model (SAM), have extended this paradigm to videos and multi-view images. However, the lack of 3D awareness often leads to inconsistent results, necessitating costly per-scene optimization to enforce 3D consistency. In this work, we introduce MV-SAM, a framework for multi-view segmentation that achieves 3D consistency using pointmaps—3D points reconstructed from unposed images by recent visual geometry models. Leveraging the pixel–point one-to-one correspondence of pointmaps, MV-SAM lifts images and prompts into 3D space, eliminating the need for explicit 3D networks or annotated 3D data. Specifically, MV-SAM extends SAM by lifting image embeddings from its pretrained encoder into 3D point embeddings, which are decoded by a transformer using cross-attention with 3D prompt embeddings. This design aligns 2D interactions with 3D geometry, enabling the model to implicitly learn consistent masks across views through 3D positional embeddings. Trained on the SA-1B dataset, our method generalizes well across domains, outperforming SAM2-Video and achieving comparable performance with per-scene optimization baselines on NVOS, SPIn-NeRF, ScanNet++, uCo3D, and DL3DV benchmarks.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->



<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Method</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- TODO: Replace with your research result images -->
        <img src="static/images/main.png" alt="We introduce a multi-view promptable segmentation framework where users can provide prompts from multi-view images." loading="lazy"/>
        <!-- TODO: Replace with description of this result -->
        <h2 class="subtitle has-text-centered">
          We introduce <span class="highlight">MV-SAM</span> where users can provide prompts in multi-view images for user-interactive segmentation.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/method.png" alt="Second research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Unlike mask propagation of SAM2-Video, which lacks 3D understanding, our <span class="highlight">MV-SAM</span> propagates all prompts in a consistent manner using pointmap.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/data.png" alt="Third research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
         By removing the reliance on 3D explicit networks or 3D inductive bias, we first train a 3D foundation model on a <span class="highlight">2D large-scale dataset</span>, SA-1B.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/qual.png" alt="Fourth research result visualization" loading="lazy"/>
      <h2 class="subtitle has-text-centered">
        Thereby, our <span class="highlight">MV-SAM</span> enables 3D promptable segmentation in various domains, demonstrating strong generalizability.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Description Video</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <video width="640" height="360" controls>
          <source src="./static/videos/video.mp4" type="video/mp4">
        </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->





<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Results</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <!-- TODO: Add poster image for better preview -->
          <video poster="" id="video1" controls muted loop height="100%" preload="metadata">
            <!-- Your video file here -->
            <source src="static/videos/sample1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <!-- TODO: Add poster image for better preview -->
          <video poster="" id="video2" controls muted loop height="100%" preload="metadata">
            <!-- Your video file here -->
            <source src="static/videos/sample2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <!-- TODO: Add poster image for better preview -->
          <video poster="" id="video3" controls muted loop height="100%" preload="metadata">
            <!-- Your video file here -->
            <source src="static/videos/sample3.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{jeong2025mvsam,
  title={MV-SAM: Multi-view Promptable Segmentation using Pointmap Guidance},
  author={Yoonwoo Jeong, Cheng Sun, Yu-Chiang Frank Wang, Minsu Cho, and Jaesung Choe},
  journal={arXiv},
  year={2025},
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- ✅ Auto-poster from first frame for all videos -->
<script>
document.addEventListener('DOMContentLoaded', () => {
  const videos = document.querySelectorAll('video');

  videos.forEach(video => {
    // 메타데이터 로드 후 첫 프레임으로 이동
    video.addEventListener('loadeddata', () => {
      try {
        video.currentTime = 0;
      } catch (e) {}
    });

    // 첫 프레임 시점에서 이미지 캡처 → poster 설정
    video.addEventListener('seeked', () => {
      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext('2d');
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const dataURL = canvas.toDataURL('image/jpeg');
      video.setAttribute('poster', dataURL);
    }, { once: true });
  });
});
</script>

    
</body>
</html>
